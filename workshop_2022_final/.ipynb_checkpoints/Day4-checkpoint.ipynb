{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAURUS + NSF REU 2022\n",
    "# Introduction to Python Day 4\n",
    "# Astropy, FITS files & Imaging\n",
    "\n",
    "Congrats on making it to the last day of this seminar! You've learned a lot in three days, so now let's put it all together to do some astronomy! \n",
    "\n",
    "A package I highly recommend you become familiar with is astropy. This includes a library of astronomical constants and unit conversions, coordinate conversions, cosmological calculations, image processing, and much more! There are many components of astropy that we won't be able to cover, but as a sneak peak you can deal with tables of data, measuring photometry, and processing psfs in images. See more here: https://docs.astropy.org/en/stable/index.html\n",
    "\n",
    "## Pip install\n",
    "\n",
    "This leads us to a great opportunity to show you how to install additional packages to your Python distribution. If it is a large, well-known package (i.e., not developed by one person on github), you can usually install things using pip. Go ahead and open a terminal session. Once you are in bash and your Python 3.5 environment, type\n",
    "\n",
    "    pip install astropy\n",
    "    \n",
    "This will automatically download and install astropy from the Internet! Note that this needs to be done outside of a Jupyter notebook (it'll throw an error if you try it). \n",
    "\n",
    "(Depending on the distribution of Python you have installed on your computer, it may or may not have come with astropy preloaded. If it's already there, then pip install will stop and say 'requirement already satisfied.')\n",
    "\n",
    "\n",
    "## Astropy: Units & Constants\n",
    "\n",
    "The most basic use for Astropy is units and constants. I highly recommend using the constants within Astropy so that a) you're not constantly Googling them, and b) they are precise and accurate. The constants are loaded with units as well, making conversions between them quite easy.\n",
    "\n",
    "One quick disclaimer is that the solar mass constant is slightly out of date, so researchers doing high-precision stellar work may need to keep that in mind.\n",
    "\n",
    "Load up the constants as well as our other usual packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import constants as const\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To call a constant, simply type const.(constant) where the symbols are generally the same as what's in your textbooks. For example, G is Newton's gravitational constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = const.G\n",
    "\n",
    "print(G)\n",
    "const.G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the constant will give you a bunch of information about it, including its name, value, uncertainty, and SI unit. Astropy is not in cgs units, but it's easy to convert by adding .cgs to the end of the unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cgs = const.G.cgs\n",
    "\n",
    "print(G_cgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert to specific units as you choose, by doing .to('new units'). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_weirdunits = const.G.to('kpc3 / (Msun Gyr2)')\n",
    "\n",
    "print(G_weirdunits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be very helpful when using normalized equations. Note that Python will have trouble with certain units: for example, it doesn't know it can cancel out Hz and seconds. Also, if there are units inside a log expression, it will complain. So if you already know your units work out and you just want the value, you can type .value!\n",
    "\n",
    "These can also be combined, like G.cgs.value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_value = const.G.value\n",
    "\n",
    "print(G_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do want to keep track of units, you can assign them by multiplying a float by the unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "\n",
    "R = 1.0 * u.kpc\n",
    "\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astropy: Cosmological Calculations\n",
    "\n",
    "There's a good chance you will need to calculate things like luminosity distance, angular diameter distance, or age of the Universe, especially if you are doing high-redshift work. To do cosmology in astropy, first set the cosmological parameters, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import FlatLambdaCDM\n",
    "\n",
    "cosmo=FlatLambdaCDM(H0=70., Om0=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets the Hubble constant to 70 km/s / Mpc and the matter density factor, $\\Omega_M$, to 0.3. The cosmological calculations are attributes of FlatLambdaCDM which we've set to \"cosmo.\" Here are a couple of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD4 = cosmo.luminosity_distance(4).to('kpc').value\n",
    "ADD4 = cosmo.angular_diameter_distance(4)\n",
    "\n",
    "print(LD4, ADD4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astropy: Sky Coordinate Systems\n",
    "\n",
    "Another fundamental part of astronomy is celestial coordinate systems. You will quickly learn that there are many ways to present the locations of objects in the sky: through right ascension and declination vs. galactic longitude and latitude for instance, or in degrees vs. hourangle, or in different frames of reference. With astropy.coordinates it is easy to convert between these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "#Say you want to define a star at 150.00 degrees, +2.00 degrees\n",
    "\n",
    "coords = SkyCoord(ra=150.0, dec=2.00, unit='deg', frame='icrs')\n",
    "\n",
    "#ICRS is common, but you might use barycentric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access other information or convert it to another format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coords.ra.hms)\n",
    "print(coords.dec.degree)\n",
    "print(coords.to_string('hmsdms'))\n",
    "\n",
    "# Can convert to galactic coordinates l, b\n",
    "coords_galactic = coords.galactic\n",
    "print(coords_galactic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matches and Separations\n",
    "\n",
    "SkyCoord objects have some pretty awesome attributes that allow you to match between two different catalogs and gives a quick and easy way to compute the separation between different objects. This comes in handy when you need to find an imaging counterpart for an emission line, or when you are checking the astrometry (coordinates) of an image.\n",
    "\n",
    "For more information click the link here: https://docs.astropy.org/en/stable/coordinates/matchsep.html\n",
    "\n",
    "The first thing we will cover is separation. It takes two Sky Coordinates objects and it will give you back the separation between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = SkyCoord(ra=150.0, dec=2.00, unit='deg', frame='icrs')\n",
    "counterpart = SkyCoord(ra=150.000056, dec=2.000043, unit='deg', frame='icrs')\n",
    "\n",
    "sep = coords.separation(counterpart)\n",
    "\n",
    "print(f'The separation of the counterpart is: {sep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also change the units of the separation with ease using the following\n",
    "\n",
    "#give separation in arcseconds\n",
    "print(f'Separation in arcseconds is: {sep:.3f}')\n",
    "\n",
    "#give separation in arcminutes\n",
    "print(f'Separation in arcminutes is: {sep:.5f}')\n",
    "\n",
    "#gives separation in degrees\n",
    "print(f'Separation in degrees is: {sep:.6}')\n",
    "\n",
    "#gives separation in radian\n",
    "print(f'Separation in radians is: {sep:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also find separation between an array of SkyCoordinates\n",
    "\n",
    "skycoord_arrays = SkyCoord(ra = np.random.uniform(100, 200, 10000) * u.degree, \n",
    "                           dec = np.random.uniform(0, 10, 10000) * u.degree)\n",
    "\n",
    "sep = coords.separation(skycoord_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can then impose conditions to find candidate counterparts by using a search radius\n",
    "\n",
    "#makes a boolean mask for us to then apply to sep variable to filter only the \n",
    "#sources that satisfy this condition\n",
    "possible_match_mask = sep.degree < 1 #searching around a 1 degree search radius\n",
    "\n",
    "print('Matches in skycoords array within 1 degree of coords:')\n",
    "skycoord_arrays[possible_match_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Catalogs\n",
    "\n",
    "The next very useful attribute of skycoords is its ability to quickly find nearby matches between two different catalogs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog1 = SkyCoord(ra = np.random.uniform(0, 360, 500) * u.degree, \n",
    "                    dec = np.random.uniform(-90, 90, 500) * u.degree)\n",
    "\n",
    "catalog2 = SkyCoord(ra = np.random.uniform(0, 360, 1000) * u.degree, \n",
    "                    dec = np.random.uniform(-90, 90, 1000) * u.degree)\n",
    "\n",
    "#the way to find matches between catalog is by using the following\n",
    "idx, sep2d, sep3d = catalog1.match_to_catalog_sky(catalog2)\n",
    "\n",
    "#idx is the index in catalog 2 that was the closest match to the coordinates in catalog1\n",
    "#sep2d is the separation between the closest match\n",
    "#sep3d the 3d separation only useful if you have distance in SkyCoord, not useful here\n",
    "\n",
    "matches_to_cat1 = catalog2[idx]\n",
    "\n",
    "close_matches_mask = sep2d.degree < 1 # checking which coordinates are w/in 1 deg of one another\n",
    "\n",
    "#applying mask to catalog 1\n",
    "print('Matches in Catalog 1 within 1 degree: ')\n",
    "print(catalog1[close_matches_mask])\n",
    "print()\n",
    "\n",
    "#applying mask to matches in catalog2\n",
    "print('Matches in Catalog 2 within 1 degree: ')\n",
    "print(matches_to_cat1[close_matches_mask])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astropy Tables\n",
    "\n",
    "The next major thing to know about is using astropy tables. These tables will be some of the data that may be stored in FITS files which we will cover in the next section. This section will teach you how to make an astropy table, and append values to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import QTable, Table, Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Table Numero 1\n",
    "\n",
    "#creates an empty table\n",
    "t = Table()\n",
    "\n",
    "#fills in the table with data with the columns being 'a', 'b', and 'c'\n",
    "# with the corresponding data for each column\n",
    "t['a'] = [1, 4]\n",
    "t['b'] = [2.0, 5.0]\n",
    "t['c'] = ['x', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Table Numero 2\n",
    "\n",
    "#we make our three columns into arrays\n",
    "a = np.array([1, 4], dtype=np.int32)\n",
    "b = [2.0, 5.0]\n",
    "c = ['x', 'y']\n",
    "\n",
    "#generate the table below with the arrays as the columns and the names of the columns\n",
    "#in the names \n",
    "t = Table([a, b, c], names=('a', 'b', 'c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Table Numero 3\n",
    "\n",
    "#this is using a mehtod called dictionaries which are a type of containers \n",
    "#they use a key to access data with the first entry the key and the next value the data\n",
    "#we can see in this one that the keys become the columns names and that the data becomes\n",
    "#the data in the columns\n",
    "arr = {'a': np.array([1, 4], dtype=np.int32),\n",
    "        'b': [2.0, 5.0],\n",
    "        'c': ['x', 'y']}\n",
    "\n",
    "Table(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no right or wrong way to generate an astropy table, it all comes down to personal preference and what data you are handling. Sometimes you do not know what data you will store so method 1 may be best, othertimes you may have data in the forms of dictionaries and so method 3 would work best here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting values from the astropy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(15).reshape(5, 3)\n",
    "t = Table(arr, names=('a', 'b', 'c'), meta={'keywords': {'key1': 'val1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['a']       # Column 'a'\n",
    "t['a'][1]    # Row 1 of column 'a'\n",
    "t[1]         # Row 1\n",
    "t[1]['a']    # Column 'a' of row 1\n",
    "t[2:5]       # Table object with rows 2:5\n",
    "t[[1, 3, 4]]  # Table object with rows 1, 3, 4 (copy)\n",
    "t[np.array([1, 3, 4])]  # Table object with rows 1, 3, 4 (copy)\n",
    "t[[]]        # Same table definition but with no rows of data\n",
    "t['a', 'c']  # Table with cols 'a', 'c' (copy)\n",
    "dat = np.array(t)  # Copy table data to numpy structured array object\n",
    "t['a'].quantity  # an astropy.units.Quantity for Column 'a'\n",
    "t['a'].to('km')  # an astropy.units.Quantity for Column 'a' in units of kilometers\n",
    "t.columns[1]  # Column 1 (which is the 'b' column)\n",
    "t.columns[0:2]  # New table with columns 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FITS Files\n",
    "\n",
    "Astropy can read in FITS files, which is a typical format of astronomical images. FITS stands for Flexible Image Transport System, and most basic image viewers can't do anything with them since they aren't files like JPGs or GIFs. There are a few programs that will read them, including CASA if you're a radio astronomer, or DS9.\n",
    "\n",
    "FITS is a useful format for astronomical data because it contains a lot of behind the scenes information. The header in particular will usually give you information about the telescope the data is from, the reference position in the sky for the data, the pixel scale, the size of the image, and more! First, let's import the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's step through how to work with the files I've given you to work with. First, open the file using fits.open(). To get some basic information about the file, type fitsfile.info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fits.open('f001a066.fits') #B filter image of Andromeda\n",
    "hdulist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual information of interest is contained in the header. FITS files can contain many images in the same file, but this is a 2D image, so it only contains one slice. We will still have to specify that it's the first slice, so we call \"hdulist[0]\". Note that you can do a shortcut in the first place and place the [0] at the end of fits.open(). \n",
    "\n",
    "Let's read out the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist[0].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know a little bit about what we're working with. You'll have to check headers pretty frequently so I'd commit this step to memory!\n",
    "\n",
    "Now we can access the data contained in the FITS file. The values are typically units of brightness and the positions in the matrix are the pixel values, with (0, 0) in the bottom left. You can manipulate this matrix like you would with any array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M51B = hdulist[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplpy\n",
    "\n",
    "My favorite way to work with images in Python is the package aplpy (pronounced Apple Pie) which allows you to make lovely publication-worthy image plots. \n",
    "\n",
    "#### Pip install aplpy, and import it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aplpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use aplpy, you don't need to go through the process of opening the FITS file and grabbing the data as in astropy. You will just open the file using FITSFigure. Let's check out this mysterious image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy = aplpy.FITSFigure('f001a066.fits')\n",
    "galaxy.show_colorscale(cmap='hot')\n",
    "galaxy.show_colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the tutorial included in the Aplpy documentation that nicely shows how you can overplot contours and include multiple layers. Take some time to play with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy = aplpy.FITSFigure('aplpy_tutorial/fits/2MASS_k.fits')\n",
    "\n",
    "galaxy.show_rgb('aplpy_tutorial/graphics/2MASS_arcsinh_color.png')\n",
    "\n",
    "galaxy.show_contour('aplpy_tutorial/fits/mips_24micron.fits')\n",
    "\n",
    "data = np.loadtxt('aplpy_tutorial/data/yso_wcs_only.txt')\n",
    "ra, dec = data[:, 0], data[:, 1]\n",
    "\n",
    "galaxy.show_markers(ra, dec, layer='marker_set_1', edgecolor='red', facecolor='none', \n",
    "                    marker='o', s=10, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Let's practice some more plotting skills, now incorporating units.\n",
    "\n",
    "A. Write a function that takes an array of frequencies and spits out the Planck distribution. That's this equation:\n",
    "\n",
    "$ B(\\nu, T) = \\frac{2h\\nu^3/c^2}{e^{\\frac{h\\nu}{k_B T}} - 1}$\n",
    " \n",
    " \n",
    "This requires you to use the Planck constant, the Boltzmann constant, and the speed of light from astropy. Make sure they are all in cgs.\n",
    "\n",
    "B. Plot your function in log-log space for T = 25, 50, and 300 K. The most sensible frequency range is about $10^5$ to $10^{15}$ Hz. Hint: if your units are correct, your peak values of B(T) should be on the order of $10^{-10}$. Make sure everything is labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Let's put everything together now! Here's a link to the full documentation for FITSFigure, which will tell you all of the customizable options: http://aplpy.readthedocs.io/en/stable/api/aplpy.FITSFigure.html. Let's create a nice plot of M51 with a background optical image and X-ray contours overplotted.\n",
    "\n",
    "The data came from here if you're interested: http://chandra.harvard.edu/photo/openFITS/multiwavelength_data.html\n",
    "\n",
    "A. Using astropy, open the X-RAY data (m51_xray.fits). Flatten the data array and find its standard deviation, and call it sigma.\n",
    "\n",
    "B. Using aplpy, plot a colorscale image of the OPTICAL data. Choose a colormap that is visually appealing (list of them here: https://matplotlib.org/2.0.2/examples/color/colormaps_reference.html). Show the colorbar. \n",
    "\n",
    "C. Plot the X-ray data as contours above the optical image. Make the contours spring green with 80% opacity and dotted lines. Make the levels go from 2$\\sigma$ to 10$\\sigma$ in steps of 2$\\sigma$. (It might be easier to define the levels array before show_contours, and set levels=levels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Spectral Analysis\n",
    "\n",
    "Code and Exercise provided to us by Olivia Cooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import ZScaleInterval\n",
    "from astropy.stats import sigma_clip\n",
    "from scipy.optimize import curve_fit\n",
    "plt.style.use('cooper-paper.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting spectra in 1D and 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll be looking at a source from a MOSFIRE program called The MOSFIRE Deep Evolution Field Survey (MOSDEF). This data set contains hundreds of galaxies (find the data here: https://mosdef.astro.berkeley.edu/for-scientists/data-releases/), but we'll look at just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the spectrum in 1D and 2D for object 2335 in the MOSDEF catalog\n",
    "\n",
    "#This is the one that has 2335.2d.fits extension\n",
    "hdu2 = fits.open('data/co2_01.H.2335.2d.fits') # 2d spectrum\n",
    "\n",
    "#This is the one that has 2335.2d.fits extension\n",
    "hdu1 = fits.open('data/co2_01.H.2335.ell.1d.fits') # 1d spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the 2D spectrum. Based on the header, we want to look at the science frame, extension 1. (If you want to see the noise frames etc, type in the appropriate index for the extension noted in the header!) I wrote a quick function to help us plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a good idea to check out the header to see how the data are set up, \n",
    "#Open up the header for the 2D file\n",
    "\n",
    "#Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_2d(image, lower=-1, upper=2):\n",
    "    \"\"\"\n",
    "    Plot grayscaled 2D spectrum\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : fits data\n",
    "        Fits data for 2D image.\n",
    "        \n",
    "    lower : float\n",
    "        Lower value to dictate vmin for grayscale. The default is -1.\n",
    "    \n",
    "    upper : float\n",
    "        Upper value to dictate vmax for grayscale. The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Plot of 2D spectrum.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sample = sigma_clip(image) \n",
    "    vmin = sample.mean() + lower * sample.std()\n",
    "    vmax = sample.mean() + upper * sample.std()\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.imshow(image, origin='lower', cmap='gray', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    plt.xlabel('Column Number')\n",
    "    plt.ylabel('Row Number')\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays the 2D spectrum\n",
    "\n",
    "show_2d(hdu2[1].data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice a few things:\n",
    "\n",
    "1) Going across the image there is a white line -- this is the continuum! That is the signal or light coming from the galaxy, all spread out in wavelength space.\n",
    "\n",
    "2) Above and below the continuum there are black lines going across. This is the negative of the signal, and is a feature we expect to see in this type of data if the signal is real (it's a product of the ABBA set-up...ask us if you want to know more!).\n",
    "\n",
    "3) There are TV static noisy vertical features -- these are the residuals of sky lines, of which there are a ton in the near-infrared! These sky lines have to be removed (as they are here) so we can extract the underlying signal from the galaxy.\n",
    "\n",
    "4) Along the continuum, there are a couple bright spots. Finding and identifying these features is our goal! These are emission lines, and based on the exact positions of these we can measure a spectroscopic redshift :-) More on this later...\n",
    "\n",
    "The rows and columns are showing the pixel scale, but there is information in the header of the FITS file that tells us how to convert from pixels to wavelength so we can precisely analyze the data. Let's do this with the 1D spectrum..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets compare the header of the 2D spectrum with the header of the 1D spectrum\n",
    "\n",
    "#Code for 1D header here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of info! Take a gander and see what you can find. (Remind us to talk about optimal vs boxcar extraction sometime if we haven't already) \n",
    "\n",
    "Of interest to us at the moment is our wavelength scaling info. We will use the information in the 1D spectra header to make our wavelength array whishc will be the first extension in hdu1.\n",
    "\n",
    "Of particular interest to us are the following keywords in the header:\n",
    "\n",
    "CRVAL1: This tells us the starting wavelength for our array \\\n",
    "CDELT1: This tells us the spacing between wavelengths (ie: the $\\Delta \\lambda$ between different pixels)\\\n",
    "NAXIS1: The length of the wavelength array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header = hdu1[].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the header data into a wavelength array\n",
    "# Generate a wavelength array using the optimal extraction extension\n",
    "# The starting value fo the wavelength array is located at\n",
    "# CRVAL1 and goes the length of the array using NAXIS1 in steps of CDELT1\n",
    "#       ENTRY1\n",
    "# Wavelength = CRVAL1 + CDELT1, ENTRY1 + CDELT1, ENTRY2 + CDELT1, ...,  \n",
    "\n",
    "\n",
    "wavelength = \n",
    "\n",
    "#Use your knowledge of Astropy hdu objects to get the spectral data\n",
    "spec1d = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have the data for the x-axis (wavelength) and for the y-axis (spectrum). Let's plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 1D spectrum\n",
    "\n",
    "plt.plot(wavelength, spec1d)\n",
    "plt.xlabel(r'Wavelength $[\\AA]$')\n",
    "plt.ylabel(r'Signal [$erg\\, s^{-1}\\, cm^{-2}\\, \\AA^{-1}$]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh...what does it mean? Basically, the way `matplotlib` has scaled this data is terrible. But that's fair, because spectra have huge noise spikes that we don't care about. So, we gotta scale better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 1D spectrum, now with a better scale\n",
    "### note, another way to do this is to multiply the signal by a factor\n",
    "### here I would use 1e17 and then set ylim from -1 to 1\n",
    "\n",
    "plt.plot(wavelength, spec1d)\n",
    "plt.xlabel(r'Wavelength $[\\AA]$')\n",
    "plt.ylabel(r'Signal [$erg\\, s^{-1}\\, cm^{-2}\\, \\AA^{-1}$]')\n",
    "\n",
    "#Play around with a scaling below so that you can see the emission features of the spectrum \n",
    "#very prominently \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's our signal!! And you may start to notice some features...it'll get easier with practice looking at spectroscopic data. And using the 1D and 2D together is essential to pick out the features in 1D!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting for a redshift\n",
    "\n",
    "Our next task is to figure out what lines we're seeing. Load in the provided line list and let's see if we can figure it out.\n",
    "\n",
    "The following cell loads in common emission, absoprtions and sky lines at various rest-frame wavelengths data from the Sloan digital Sky Survey (SDSS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of spectral lines (originally from SDSS)\n",
    "### shows the vacuum (rest) wavelength, the species, and the type of line\n",
    "\n",
    "lines = pd.read_csv('linelist.csv',delimiter=\",\",comment='#') # all lines\n",
    "em = lines[lines['type']=='Emission'] # emission lines\n",
    "ab = lines[lines['type']=='Absorption'] # absorption lines\n",
    "sky = lines[lines['type']=='Sky'] # absorption lines\n",
    "\n",
    "em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these lines to figure out the redshift of the galaxy we are looking at. Redshift is an astronomical term that basically tells us how much the light from a galaxy has been stretched due to the expansion of the universe. I more nearby galaxy will have little stretch and will have a low redshift where a galaxy further away will have its light stretched more and will have a higher redshift. \n",
    "\n",
    "Our task is to take the lines that we loaded in and determine the redshift of the source. We will do this by guessing where the lines should be for a given redshift.\n",
    "\n",
    "Your task is to input a guess for redshift in for zguess below and try to match up line features in the spectrum, Matching the emission features with spikes, and absorption features with dips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pay attention to the scaling here!\n",
    "# your task: change zguess until the lines match up with the features :-) \n",
    "\n",
    "zguess =  ## adjust the redshift!\n",
    "\n",
    "plt.plot(wavelength, spec1d*1e17)\n",
    "plt.xlabel(r'Wavelength $[\\AA]$')\n",
    "plt.ylabel(r'Signal [$10^{-17} erg\\, s^{-1}\\, cm^{-2}\\, \\AA^{-1}$]')\n",
    "\n",
    "plt.xlim(15500,17000)\n",
    "plt.ylim(-0.5,1.5)\n",
    "\n",
    "#Plotting the lines\n",
    "plt.plot(ab['lambda']*(1+zguess),0*np.ones_like(ab['lambda']),'kv',ms=3,label='absorption')\n",
    "plt.plot(em['lambda']*(1+zguess),0*np.ones_like(em['lambda']),'k^',ms=3,label='emission')\n",
    "plt.plot(sky['lambda']*(1+zguess),0*np.ones_like(sky['lambda']),'kd',ms=3,label='sky')\n",
    "\n",
    "#this is code that draws an arrow for us to visually see them lining up\n",
    "for i in range(len(lines['lambda'])):\n",
    "    plt.annotate(str(lines['species'][i]+', '+str(lines['lambda'][i])),xy=(lines['lambda'][i]*(1+zguess), 0),\\\n",
    "                xytext=(lines['lambda'][i]*(1+zguess)-10, 1),arrowprops=dict(arrowstyle=\"-\",),size=7,rotation=90)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Exact Redshift Estimate\n",
    "\n",
    "Doing things by eye is a great first start but our eyes cannot see down to very fine details. For exact science and a more robust prediction on the redshift we need to use fitting techniques to fit the emission line and get a better measurment of the peak emission wavelength. For that we will use $\\textbf{Model Fitting}$.\n",
    "\n",
    "Your goal is to fit an emission line of your choosing with a Gaussian and provide us with the wavelength and the spectrosopic redshift of the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step is to make the model of our Gaussian \n",
    "# Complete the function definition of this Gaussian\n",
    "# Look back to Day 3 for definition of a Gaussian or feel free to google it\n",
    "# Just note what each parameter in this gaussian is in the context of the spectra\n",
    "\n",
    "# x = wavelength\n",
    "# sigma = broadness of the emission line\n",
    "# A = amplitude of the emission line\n",
    "# mu = central wavelength of the gaussian\n",
    "\n",
    "def gaussian():\n",
    "    '''\n",
    "    Function declaration for a Gaussian\n",
    "    \n",
    "    Input(s)\n",
    "    ----------\n",
    "    \n",
    "    \n",
    "    Output(s)\n",
    "    -------------\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fit a gaussian to find line center\n",
    "# we need to make a cut so the fit only uses data around the line we want to fit\n",
    "# As an example you may want to fit the emission line near 16400 Angstroms and select \n",
    "# a window of 100 angstroms on either side\n",
    "# Hint: use np.where() here and apply it to both wavelength and spectrum array\n",
    "\n",
    "wav = wavelength[]\n",
    "spec = spec1d[] * 1e17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next step is to fit the line and for that we need you to provide us with a best guess \n",
    "#for every parameter\n",
    "\n",
    "#      Guess_amplitude, Guess_center, Guess_sigma \n",
    "# (Note that the order of guesses will depend on how you defined your gaussian function)\n",
    "\n",
    "guess = \n",
    "\n",
    "#       provide some bounds for your fit. \n",
    "# Note that this will need to be in the same order as your guesses\n",
    "bounds = ((, , ), (, , ))\n",
    "\n",
    "#fitting spectrum with a gaussian\n",
    "popt, pcov = curve_fit(gaussian, wav, spec, p0=guess, bounds=bounds)\n",
    "\n",
    "\n",
    "obswav = popt[]\n",
    "obswav_error = np.sqrt(pcov[, ])\n",
    "print(f'Observed wavelength of OII [5008] is {obswav:.3f} +/- {obswav_error:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the redshift\n",
    "\n",
    "restwav = \n",
    "redshift = obswav / restwav - 1\n",
    "print(f'The redshift is {redshift:.4f} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
