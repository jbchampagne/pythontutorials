{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAURUS + NSF REU 2022\n",
    "# Introduction to Python Day 3\n",
    "# Statistics, Interpolation & Fitting Data\n",
    "\n",
    "Welcome back again! So far we have covered basic syntax, arrays, if statements, for loops, functions, and plotting. Now we can start building some data analysis skills using statistics. \n",
    "\n",
    "Python has lots of built in functions for generating random data. Today let's start with generating random values from a Gaussian distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = np.random.normal(0, 2, 1000) \n",
    "#Gaussian centered on 0 with a std. dev. of 2, sampled 1000 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms \n",
    "\n",
    "A plot you'll probably make quite often is a histogram. For this, use plt.hist().\n",
    "\n",
    "    plt.hist(data, bins, stacked=True/False, density=True/False)\n",
    "    \n",
    "The \"bins\" argument can either be an array, or simply setting \"bins=x\" for a number of evenly spaced bins. Setting stacked and density to True will normalize your data to sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gaussian, bins=20, stacked=True, density=True)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with normal plotting, there are lots of customizable options for histograms, including:\n",
    "\n",
    "    facecolor: string argument giving color of histogram\n",
    "    edgecolor: string argument giving edge color\n",
    "    alpha: opacity, ranging from 0 to 1\n",
    "    hatch: a histogram filling style, such as '\\\\', '//', '.', '..', etc\n",
    "    histtype: bar, step\n",
    "    density: True/False\n",
    "    stacked: True/False\n",
    "    cumulative: True/False\n",
    "    \n",
    "Full details here: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html\n",
    "    \n",
    "## Gaussian Fitting\n",
    "\n",
    "Let's try fitting the Gaussian. This is a little bit redundant since we already know it's a Gaussian distribution, but this example should illustrate how the fitting process works. Let's use a package from scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro-tip: if you're ever unsure about how to use a function, type ? after the function name to call up the docstrings.\n",
    "\n",
    "To fit a Gaussian, simply use norm.fit(data). This will return the mean and standard deviation of the fit. np.average() and np.std() will give the mean and standard deviation of the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = norm.fit(gaussian)\n",
    "print(mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did pretty well. It performs better the larger the sample you give it. \n",
    "\n",
    "Next, to overplot the Gaussian fit, you can calculate the probability density function (PDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 1000)\n",
    "pdf = norm.pdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, pdf, 'k-', linewidth=2)\n",
    "plt.hist(gaussian, bins=50, color='mediumpurple', alpha=0.4, density=True, fill=True, histtype='step')\n",
    "plt.title(\"Fit results: $\\mu$ = %.2f, $\\sigma$ = %.2f\" % (mu, sigma)) \n",
    "#Pro-tip: this prints out the values of mu and sigma to 2 decimal places.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating Data\n",
    "\n",
    "You may encounter a situation in your research where you will need to interpolate a model to interpret your data. The scipy library has many different interpolating (and extrapolating) algorithms, but the simplest is a 1D interpolation, called interp1d. \n",
    "\n",
    "Let's first generate a well-behaved function that will be easy to interpolate along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarray = np.linspace(-4*np.pi, 4*np.pi, 30)\n",
    "yarray = np.sin(xarray)\n",
    "\n",
    "plt.plot(xarray, yarray, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about this plot? Well, at first glance it doesn't really look like a sine curve because it is poorly sampled. Of course, since we already know it's a sine curve, we could just sample the function better, but say you didn't have such a nice function. Interp1d comes to the rescue! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few steps to interpolation. First, the interp1d function interpolates your original y array. Then, you need to define the new array along which to interpolate, which must completely fit inside the original array (or else it's extrapolation). We'll take the same array but grid it more finely. Finally, you create a new y array using the interpolated function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = interp1d(xarray, yarray)\n",
    "xnew = np.linspace(-4*np.pi, 4*np.pi, 1000)\n",
    "ynew = interp(xnew)\n",
    "\n",
    "plt.plot(xnew, ynew, '--')\n",
    "plt.plot(xarray, yarray, 'or')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it looks much closer to a sine curve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data files into Python \n",
    "\n",
    "Up until now, none of the exercises have required you to load in an outside file to the notebook, but this is definitely something you'll need to learn! You can use np.genfromtxt, np.loadtxt, or a library called pandas if you're feeling advanced. \n",
    "\n",
    "If your file is just a 1D array of floats, then simply defining a variable with np.genfromtxt('filename') will suffice. Other arguments include \"dtype\" which allows you to specify that they're strings or integers, and in a moment I'll show you how to transpose a text file.\n",
    "\n",
    "First let's load up the spectrum we are going to work with. Python reads by rows, not columns, but if you want separate arrays indicating the columns such as wavelengths, flux, and flux errors, you can transpose it, by doing np.genfromtxt('filename').T. You can define it all in one line, like so:\n",
    "\n",
    "x, y, z = np.genfromtxt('file_with_three_columns.txt').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load up the file \"test_spectrum.txt\", whose three columns are wavelength, flux, and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Spectrum\n",
    "\n",
    "Finally we can put what we've learned together to do a real life astronomy example! We will do this exercise together.\n",
    "\n",
    "Here is a sample spectrum which features a prominent spectral emission line. Our job will be to fit the line with a Gaussian model to compute its peak flux and FWHM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot up what we have so far. This is a great opportunity to show you another useful plotting tool: errorbars! \n",
    "\n",
    "Instead of doing plt.plot, you can do plt.errorbar, which plots both the data and the errorbars. The first two arguments are x and y like in plt.plot, and the next two arguments are xerr and yerr. You can specify the color of the errorbars using the keyword argument (kwarg) \"ecolor\", and you can put hats on the errorbar with \"capsize.\"\n",
    "\n",
    "### Plot the spectrum with y errors (it doesn't have x errors) with the data in blue and the errorbars in magenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your plot here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the optimize function from scipy. This allows you to fit pretty much any kind of function you want, but here we know that the emission line has a Gaussian profile. \n",
    "\n",
    "Many spectral lines are well-described by a Gaussian curve, and lines that deviate from a Gaussian are often astronomically interesting. So the first step in many spectroscopic projects is to see if your line is Gaussian.\n",
    "\n",
    "$N(x, \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "This means that $\\mu$, the mean of the Gaussian, is the wavelength at which the line peaks. This helps you decide what line it is (Ly$\\alpha$, carbon monoxide, nitrogen, etc.)\n",
    "\n",
    "$\\sigma$ is the width of the line -- spectral lines have natural shifts a bit to the left and a bit to the right of the \"true\" wavelength it should peak at. There are astronomical reasons why your line would be extremely wide, or skewed to one side.\n",
    "\n",
    "f0 is the peak height of the line, or the flux at which your line peaks -- how bright your astronomical object is. The reason we call it \"f0\" instead of the full Gaussian term is we don't want it to get caught up in the value of $\\sigma$.\n",
    "\n",
    "$N(x, f_0, \\mu, \\sigma) = f_0 e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "### Import the optimize function from scipy as \"opt.\" Using what you learned yesterday, define a Gaussian function which takes as its arguments x, $f_0$, $\\mu$, and $\\sigma$. (Here, $f_0$ is a normalizing factor in front of the Normal distribution, used in place of the $(\\sigma * \\sqrt{2 \\pi})^{-1}$ term.) When you use optimize, it's important that the first argument is the array you're fitting along, so here that is x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your function here\n",
    "\n",
    "# define your gaussian here (hint: if you did your homework you did this already!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimize function finds the best fit parameters as well as the covariance matrix for those parameters. p0 is the initial guess for the fit - this is important because a bad or no first guess will cause a bad fit. So the rest of the fit goes like so:\n",
    "\n",
    "See if you can guess a good p0!\n",
    "\n",
    "*Make sure the order of p0 is the same as the order of the arguments in the function!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfpars, covar = opt.curve_fit(gauss, wave, flux, p0=[10700, 100, 2.0e-18], sigma=error) #edit p0\n",
    "\n",
    "print(bfpars)\n",
    "#so now we see the line peaks at 10,704 Angstrom, it has a width of 219 Angstrom, \n",
    "#and it has a peak flux of 1.88e-18 erg s^-1 cm^-2 AA^-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Bfpars\" is now an array containing the best fit parameters, in the same order as your function. So in my case, bfpars[0] is $\\mu$, bfpars[1] is $\\sigma$, and bfpars[2] is f0.\n",
    "\n",
    "Try printing out the best fit parameters. Do the values make sense to you? \n",
    "\n",
    "Let's define a higher resolution wavelength grid we can use to overlay the fit. We can also zoom in on the line since the rest of the spectrum is noise.\n",
    "\n",
    "Below, x should be a grid that is centered on $\\mu$, and is plotted from -10$\\sigma$ to 10$\\sigma$ (so make sure your index values are correct, depending on how you defined the Gaussian function -- mine has $\\mu$, $\\sigma$, f0 in that order).  This just means I want you to evaluate the Gaussian right where the emission line occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(bfpars[0]-10*bfpars[1], bfpars[0]+10*bfpars[1], 1000) \n",
    "#Center the grid on the wavelength of the line\n",
    "#and go +- 10*sigma from there\n",
    "\n",
    "modelfit = gauss(x, bfpars[0], bfpars[1], bfpars[2]) \n",
    "#This is the Gaussian curve with the best fit parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data Files\n",
    "\n",
    "The syntax for writing files is similar to loading them, with many customizable options in np.savetxt(filename, data). The arguments are as follows:\n",
    "\n",
    "    fname: the path and filename you want to save to\n",
    "    X: the array(s) being saved\n",
    "    fmt: the format of each column of data, e.g. \"%s\" for strings or \"%.2f\" for a floating point with 2 decimal places\n",
    "    delimiter: can leave this blank for evenly spaced columns, but you could use ',' for comma-separated values\n",
    "    header: a string that might contain info about the file or the names of columns, like '# ra dec velocity'\n",
    "    \n",
    "    \n",
    "Save the modelfit parameters to a text file in this directory.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your final task, plot the model over the data by including both plots in the same cell, and make sure you zoom in on the line by choosing a wise range for xlim. \n",
    "\n",
    "Spectra are typically viewed along a long x-axis: try changing the figure size.\n",
    "\n",
    "Congrats, you've done your first bit of science with Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a file in this directory called \"histogram_exercise.dat\" which consists of of randomly generated samples from a Gaussian distribution with an unknown $\\mu$ and $\\sigma$. Using what you've learned about fitting data, load up this file using np.genfromtxt, fit a Gaussian curve to the data and plot both the curve and the histogram of the data. As always, label everything, play with the colors, and choose a judicious bin size.\n",
    "\n",
    "Hint: if you attempt to call a function from a library or package that hasn't been imported, you will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Interpolation\n",
    "\n",
    "Create a 1D interpolation along these arrays.\n",
    "\n",
    "a. Plot both the data (as points) and the interpolation (as a dotted line).\n",
    "\n",
    "b. Also plot the value of the interpolated function at x=325. What does the function look like to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0., 50., 100., 150., 200., 250., 300., 350., 400., 450., 500])\n",
    "y = np.array([0., 7.071, 10., 12.247, 14.142, 15.811, 17.321, 18.708, 20., 21.213, 22.361])\n",
    "\n",
    "#Solution Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 3: MCMC\n",
    "\n",
    "A big part of astronomy is moving towards implementing Bayesian techniques. These techniques are useful as you can use prior information to inform new predictions, can assess the likelihod of the data you collected and provides a natural way to quantify the uncertainty on derived parameters. For this problem we will code up our very own MCMC algorithm using a technique called Metropolis Hastings algorithm.\n",
    "\n",
    "We will walk throught he steps of how it works and you are tasked with translating it into code.\n",
    "\n",
    "The Metropolis Hasting Sampling algorithm is an algorithm that takes your current start position and checks it against a trial value which we specify by inorporating a jump size to jump from our current value to another one. We then check to see if the new trial is more likely than the other one and if it is we keep the value but if it is not we reject the trial and stay at the current value and try again. We do this until we store our 10,000 values. \n",
    "\n",
    "For this problem we want to use MCMC to fit the Mass-Radius relation for M-dwarf Stars and see what values for the slope and y-intercept we get. The Mass-Radius relation is given by $R(M) = aM + b$ and our job is to find the best fit a and b values for the given data. In the directory is a file titled MCMC_Data.txt you will use this as this has the R, M and $\\sigma_R$ values which you will need in the MCMC below. \n",
    "\n",
    "\n",
    "Steps: \n",
    "\n",
    "1. We need to decide how many values we want to ultimately aquire as part of the MCMC, it is good practice to start small so say L = 100 and then once the code works increase it to L = 100,000\n",
    "2. We will need to jump from our current value to a test value so for this we need to specify a jump size which will be done by randomly generating a test value from a gaussian centered on your current value with a standard devation which we will provide use [$\\sigma_a = 0.002, \\sigma_b = 0.001$]\n",
    "3. Come up with an initial guess for the parameters, i recommend starting the slope at a value near 1.04 and the y-intercept at 0.001. But feel free to play around with these starting values. But do note the step size of your $\\sigma$ values as this assumes that you were close to the correct value. \n",
    "4. Start a loop and specify it to stop after you have accepted the number L from Part 1. It should start off as a [1 X 2] matrix but you will eventually generate an [L X 2] Matrix.\n",
    "5. Now we need to vary one parameter and check if we accept it or reject it. At this stage generate a random number between 0-1 and round it. This will be the parameter to vary as a 0 means you will vary the first value and 1 means you will vary the second value\n",
    "6. Now that we have which parameter we will vary we need to draw a trial value, to select a trial value we take the current value and draw from a gaussian with the corresponding $\\sigma$ from step 2. So if the first value is the one that gets varied you have a current trial [$a_c, b_c$] and your trial test is [$a_t, b_c$] with $a_t$ being a random number drawn from the Gaussian $a_t = N(\\mu = a_c, \\sigma = \\sigma_a)$, if the second value is varied then you sample from a Gaussian $b_t = N(\\mu = b_c, \\sigma = \\sigma_b)$ and have [$a_c, b_t$].\n",
    "7. The goal is to compare which value has the highest likelihood between the current or trial values(ie: comparing [$a_c, b_c$] to [$a_t, b_c$] or [$a_c, b_c$] to [$a_c, b_t$]). At this step generate two sets of model predictions for the given $x_i$. One with the current parameter values $m_{c, i} = a_c x_i + b_c$ and another with the trial parameter values $m_{t, i} = a_t x_i + b_c$ if the first parameter is changing, $m_{t, i} = a_c x_i + b_t$ if the second parameter is changing)\n",
    "8. Compute the $\\chi^2$ for the current and trial runs using $\\chi_c^2 = \\sum_i^N \\frac{(R_i - m_{c, i})^2}{\\sigma_{R, i}^2}$ and trial run being $\\chi_t^2 = \\sum_i^N \\frac{(R_i - m_{t, i})^2}{\\sigma_{R, i}^2}$\n",
    "9. Compute the ratio r = $e^{-\\chi_t^2/2}/e^{-\\chi_c^2/2} = e^{-(\\chi_t^2 - \\chi_c^2)/2}$\n",
    "10. Draw a random number P from a uniform distribution between 0 and 1, then compare if P < r (from part 9) and if it is accept the trial values and add them to your matrix, if P > r we reject the trial values and start from step 5 again\n",
    "11. Repeat steps 5-10 until you reach the desired L from part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data from the MCMC_Chain.txt file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    \n",
    "    '''\n",
    "    This will be the function that we will want to fit. In this particular example \n",
    "    we want to fit the Mass-Radius Relation R(M) = aM + b\n",
    "    \n",
    "    Inputs\n",
    "    ----------------\n",
    "    \n",
    "    \n",
    "    Output(s)\n",
    "    ----------------\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "def Chi2():\n",
    "    \n",
    "    '''\n",
    "    Function that will compute the chi2 for a given R, R_err, and model\n",
    "    R and R_err are given in the MCMC_Chain.txt file\n",
    "    \n",
    "    Inputs\n",
    "    -----------\n",
    "    \n",
    "    \n",
    "    Output(s)\n",
    "    -----------\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dummy array that will store the values of the MCMC Chain\n",
    "# This should be an L x 2 array/matrix\n",
    "# eventually the L should be 100000 but start of with 100 to make sure the code is working\n",
    "# then work up to L of 100000\n",
    "MCMC_chains = np.zeros()\n",
    "\n",
    "# Sigma Declarations defined above\n",
    "sigmas = [ , ]\n",
    "\n",
    "##############\n",
    "#Write the Metropolis-Hasting Sampling Algorithm here\n",
    "##############\n",
    "\n",
    "# Initial Starting Values\n",
    "values = [1.04, 0.001]\n",
    "\n",
    "#This counter will be the index for the rows in the MCMC chains that get accepted\n",
    "#be sure to update this as this will keep track of how many chains get accepted \n",
    "counter = 0\n",
    "\n",
    "#Decide which loop you want to use for this (ie: For-Loop/While-Loop) Think about the \n",
    "#acceptance will we always accept?\n",
    "\n",
    "    # In the Loop\n",
    "    # Generate a random number from 0-1 and round it, if 0 we will alter the a-parameter\n",
    "    # if 1 we will alter the b-parameter\n",
    "\n",
    "    #Now that you have which parameter we will vary\n",
    "    #generate a new trial parameter by sampling from a gaussian \n",
    "    #centered on the current value with the appropriate sigma for the parameter\n",
    "    \n",
    "    #generate two model predictions\n",
    "    #1. using the current parameter values\n",
    "    #2. using the trial parameters\n",
    "    \n",
    "    #Compute the chi2 between the two models\n",
    "    \n",
    "    #Compute the ratio r defined above\n",
    "    \n",
    "    # Randomly sample from a uniform distribution between 0-1 and compare \n",
    "    # the random sample to the ratio r\n",
    "    # if the random number is less than r \n",
    "    # We accept the trial parameters and store them in the MCMC_chains variable\n",
    "    # if the random number is larger than r we reject and keep the current parameters\n",
    "    #Then we try again note that we do not store here\n",
    "    \n",
    "    #repeat these steps in the loop until your MCMC chain has the desired L entries\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#During the MCMC fitting we need to get rid of the first few 1000 entries\n",
    "#the reason for this is that the chain had not yet converged so we remove these\n",
    "#with an L of 100000 remove the first 10000 values\n",
    "\n",
    "param1_burnin = #this would be column 1 in MCMC_chain\n",
    "param2_burnin = #this would be column 2 in MCMC_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check if our values have converged lets plot them\n",
    "plt.figure(figsize = (12, 7))\n",
    "plt.plot(param1_burnin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check if our values have converged lets plot them\n",
    "plt.figure(figsize = (12, 7))\n",
    "plt.plot(param2_burnin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If everything ran correctly these should look like shot noise \n",
    "#we can then make these into distributions and quantify the median as our value \n",
    "#and the error as the 16th and 84th percentile interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a histogram of each quantity and make sure to make the plot as informative as possible\n",
    "#ie: include title, x and y labels and any legends if necessary\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
